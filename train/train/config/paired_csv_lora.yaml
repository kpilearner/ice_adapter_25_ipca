flux_path: "black-forest-labs/flux.1-fill-dev"
dtype: "bfloat16"

model:
  union_cond_attn: true
  add_cond_attn: false
  latent_lora: false
  use_sep: false

train:
  batch_size: 2
  accumulate_grad_batches: 1
  dataloader_workers: 4
  save_interval: 1000
  sample_interval: 0
  max_steps: -1
  gradient_checkpointing: true
  save_path: "runs"

  dataset:
    # Kontext-like local training format: a CSV that points to image pairs + prompt.
    # Default column names match DiffSynth's Kontext example:
    # - `kontext_images`: source/context image (e.g., visible)
    # - `image`: target image (e.g., infrared)
    # - `prompt`: instruction (can be constant across rows)
    type: "paired_csv"
    base_path: "data/vis_ir"
    metadata_path: "data/vis_ir/metadata.csv"
    source_key: "kontext_images"
    target_key: "image"
    prompt_key: "prompt"
    default_prompt: "convert to infrared image."
    condition_size: 512
    target_size: 512
    drop_text_prob: 0.0

  loss:
    use_masked_loss: true
    masked_weight: 1.0
    unmasked_weight: 0.0
    t_sampling: "uniform"

  adapter:
    enabled: true
    dim: 768
    hidden_dim: 3072
    scale: 1.0

  lora_config:
    r: 32
    lora_alpha: 32
    init_lora_weights: "gaussian"
    target_modules: "(.*x_embedder|.*(?<!single_)transformer_blocks\\.[0-9]+\\.norm1\\.linear|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.to_k|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.to_q|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.to_v|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.to_out\\.0|.*(?<!single_)transformer_blocks\\.[0-9]+\\.ff\\.net\\.2|.*single_transformer_blocks\\.[0-9]+\\.norm\\.linear|.*single_transformer_blocks\\.[0-9]+\\.proj_mlp|.*single_transformer_blocks\\.[0-9]+\\.proj_out|.*single_transformer_blocks\\.[0-9]+\\.attn.to_k|.*single_transformer_blocks\\.[0-9]+\\.attn.to_q|.*single_transformer_blocks\\.[0-9]+\\.attn.to_v|.*single_transformer_blocks\\.[0-9]+\\.attn.to_out)"

  optimizer:
    type: "AdamW"
    params:
      lr: 1.0e-4
      betas: [0.9, 0.999]
      weight_decay: 0.01
