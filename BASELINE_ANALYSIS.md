# ICEdit Baseline ä»£ç è§£æ

> å¿«é€Ÿå‚è€ƒæ–‡æ¡£ - ç”¨äºç†è§£å’Œä¿®æ”¹ICEdité¡¹ç›®

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
ICEdit_raw/
â”œâ”€â”€ scripts/                    # æ¨ç†å’Œæ¼”ç¤ºè„šæœ¬
â”‚   â”œâ”€â”€ inference.py           # â­ åŸºç¡€æ¨ç†è„šæœ¬
â”‚   â”œâ”€â”€ inference_moe.py       # MoE-LoRAç‰ˆæœ¬æ¨ç†
â”‚   â”œâ”€â”€ gradio_demo.py         # Gradio Webç•Œé¢
â”‚   â””â”€â”€ config.json
â”‚
â”œâ”€â”€ train/                      # â­ è®­ç»ƒä»£ç åº“
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ train/             # è®­ç»ƒæ ¸å¿ƒæ¨¡å—
â”‚   â”‚   â”‚   â”œâ”€â”€ model.py      # â­â­ OminiModelå®šä¹‰
â”‚   â”‚   â”‚   â”œâ”€â”€ data.py       # â­â­ æ•°æ®é›†åŠ è½½å™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py      # â­â­ ä¸»è®­ç»ƒè„šæœ¬
â”‚   â”‚   â”‚   â””â”€â”€ callbacks.py  # è®­ç»ƒå›è°ƒ(ä¿å­˜/æ—¥å¿—)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ flux/              # FLUXæ¨¡å‹ç»„ä»¶
â”‚   â”‚       â”œâ”€â”€ transformer.py
â”‚   â”‚       â”œâ”€â”€ condition.py
â”‚   â”‚       â”œâ”€â”€ pipeline_tools.py
â”‚   â”‚       â””â”€â”€ lora_controller.py
â”‚   â”‚
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”œâ”€â”€ normal_lora.yaml  # â­ è®­ç»ƒé…ç½®
â”‚   â”‚   â”‚   â””â”€â”€ moe_lora.yaml
â”‚   â”‚   â””â”€â”€ script/
â”‚   â”‚       â””â”€â”€ train.sh          # â­ è®­ç»ƒå¯åŠ¨è„šæœ¬
â”‚   â”‚
â”‚   â””â”€â”€ parquet/               # æ•°æ®é›†å­˜å‚¨
â”‚       â””â”€â”€ prepare.sh         # æ•°æ®ä¸‹è½½è„šæœ¬
â”‚
â”œâ”€â”€ assets/                    # ç¤ºä¾‹å›¾åƒ
â””â”€â”€ README.md
```

---

## ğŸ”‘ æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. **æ¨¡å‹æ¶æ„** (`train/src/train/model.py`)

**ç±»**: `OminiModel(L.LightningModule)`

#### å…³é”®å±æ€§:
```python
- flux_fill_pipe: FluxFillPipeline  # åŸºç¡€FLUXæ¨¡å‹
- transformer: FluxTransformer       # ä¸»å¹²ç½‘ç»œ
- text_encoder: CLIP                 # æ–‡æœ¬ç¼–ç å™¨
- text_encoder_2: T5                 # T5æ–‡æœ¬ç¼–ç å™¨
- lora_layers: List[Parameter]       # LoRAå¯è®­ç»ƒå‚æ•°
```

#### å…³é”®æ–¹æ³•:

| æ–¹æ³• | åŠŸèƒ½ | ä»£ç ä½ç½® |
|------|------|----------|
| `__init__()` | åˆå§‹åŒ–FLUXæ¨¡å‹ + æ·»åŠ LoRA | 14-51è¡Œ |
| `init_lora()` | é…ç½®LoRAé€‚é…å™¨ | 53-64è¡Œ |
| `save_lora()` | ä¿å­˜LoRAæƒé‡ | 66-74è¡Œ |
| `configure_optimizers()` | è®¾ç½®Prodigyä¼˜åŒ–å™¨ | 76-101è¡Œ |
| `training_step()` | å•æ­¥è®­ç»ƒ | 103-110è¡Œ |
| `step()` | â­â­ **æ ¸å¿ƒè®­ç»ƒé€»è¾‘** | 112-160è¡Œ |

#### **è®­ç»ƒæµç¨‹** (ç¬¬112-160è¡Œ):
```python
1. è·å–batchæ•°æ®
   - imgs: ç›®æ ‡å›¾åƒ (ç¼–è¾‘å)
   - mask_imgs: maskå›¾åƒ
   - prompts: ç¼–è¾‘æŒ‡ä»¤

2. ç¼–ç  (with torch.no_grad)
   - prompt_embeds â† prepare_text_input(prompts)
   - x_0, x_cond, img_ids â† encode_images_fill(imgs, mask_imgs)

3. æµåŒ¹é…é‡‡æ ·
   - t ~ Sigmoid(N(0,1))          # æ—¶é—´æ­¥
   - x_1 ~ N(0,1)                 # çº¯å™ªå£°
   - x_t = (1-t)*x_0 + t*x_1     # æ’å€¼

4. å‰å‘ä¼ æ’­
   - input = concat(x_t, x_cond)  # æ‹¼æ¥æ¡ä»¶
   - pred = transformer(input, t, prompt_embeds)

5. è®¡ç®—æŸå¤±
   - loss = MSE(pred, x_1 - x_0)  # é¢„æµ‹é€Ÿåº¦åœº
```

---

### 2. **æ•°æ®å¤„ç†** (`train/src/train/data.py`)

#### ä¸‰ä¸ªæ•°æ®é›†ç±»:

| ç±»å | æ•°æ®æº | ç”¨é€” |
|------|--------|------|
| `EditDataset` | MagicBrush (train+dev) | ä»…MagicBrush |
| `OminiDataset` | OmniEdit (parquet) | ä»…OmniEdit |
| `EditDataset_with_Omini` | MagicBrush + OmniEdit | â­ **æ··åˆæ•°æ®é›†** |

#### **æ•°æ®æ ¼å¼å¤„ç†** (å…³é”®ä»£ç : ç¬¬49-83è¡Œ):

```python
# 1. è¯»å–æ•°æ®
source_img = dataset["source_img"]        # åŸå§‹å›¾åƒ
target_img = dataset["target_img"]        # ç¼–è¾‘åå›¾åƒ
instruction = dataset["instruction"]      # ç¼–è¾‘æŒ‡ä»¤

# 2. è°ƒæ•´å°ºå¯¸
source_img = source_img.resize((512, 512)).convert("RGB")
target_img = target_img.resize((512, 512)).convert("RGB")

# 3. åˆ›å»ºDiptych (å·¦å³æ‹¼æ¥)
combined_image = Image.new('RGB', (1024, 512))
combined_image.paste(source_img, (0, 0))    # å·¦åŠéƒ¨åˆ†
combined_image.paste(target_img, (512, 0))  # å³åŠéƒ¨åˆ†

# 4. åˆ›å»ºMask (æ ‡è®°ç¼–è¾‘åŒºåŸŸ)
mask = Image.new('L', (1024, 512), 0)
draw.rectangle([512, 0, 1024, 512], fill=255)  # å³åŠéƒ¨åˆ†=255

# 5. æ„é€ Prompt
prompt = "A diptych with two side-by-side images of the same scene. " \
         "On the right, the scene is exactly the same as on the left but " + instruction

# 6. è¿”å›
return {
    "image": to_tensor(combined_image),    # [3, 512, 1024]
    "condition": to_tensor(mask),          # [1, 512, 1024]
    "description": prompt,
}
```

#### é‡è¦å‚æ•°:
- `condition_size = 512`: å›ºå®šå®½åº¦
- `drop_text_prob = 0.1`: 10%æ¦‚ç‡ä¸¢å¼ƒæ–‡æœ¬(ç”¨äºCFGè®­ç»ƒ)
- `crop_the_noise = True`: è£å‰ªMagicBrushåº•éƒ¨å™ªå£°

---

### 3. **è®­ç»ƒé…ç½®** (`train/train/config/normal_lora.yaml`)

```yaml
# æ¨¡å‹è·¯å¾„
flux_path: "black-forest-labs/flux.1-fill-dev"
dtype: "bfloat16"

# è®­ç»ƒå‚æ•°
train:
  batch_size: 2                    # æ¯GPUæ‰¹æ¬¡å¤§å°
  accumulate_grad_batches: 1       # æ¢¯åº¦ç´¯ç§¯
  dataloader_workers: 5
  save_interval: 1000              # æ¯1000æ­¥ä¿å­˜
  sample_interval: 1000            # æ¯1000æ­¥é‡‡æ ·
  gradient_checkpointing: true     # æ¢¯åº¦æ£€æŸ¥ç‚¹(çœæ˜¾å­˜)

  # æ•°æ®é›†
  dataset:
    type: "edit_with_omini"        # â­ ä½¿ç”¨æ··åˆæ•°æ®é›†
    path: "parquet/*.parquet"      # OmniEditæ•°æ®è·¯å¾„
    condition_size: 512
    target_size: 512
    drop_text_prob: 0.1            # CFGè®­ç»ƒ

  # LoRAé…ç½®
  lora_config:
    r: 32                          # LoRA rank
    lora_alpha: 32                 # LoRAç¼©æ”¾å› å­
    init_lora_weights: "gaussian"
    target_modules: "(.*x_embedder|...|.*single_transformer_blocks\\.[0-9]+\\.attn.to_out)"
    # â­ æ­£åˆ™åŒ¹é…ç›®æ ‡æ¨¡å—:
    # - x_embedder
    # - transformer_blocks: norm1, attn (q/k/v/out), ff
    # - single_transformer_blocks: norm, proj_mlp/out, attn

  # ä¼˜åŒ–å™¨
  optimizer:
    type: "Prodigy"                # è‡ªé€‚åº”ä¼˜åŒ–å™¨
    params:
      lr: 1                        # Prodigyæ¨èlr=1
      weight_decay: 0.01
```

---

### 4. **æ¨ç†æµç¨‹** (`scripts/inference.py`)

```python
# 1. åŠ è½½æ¨¡å‹
pipe = FluxFillPipeline.from_pretrained("black-forest-labs/flux.1-fill-dev")
pipe.load_lora_weights("RiverZ/normal-lora")  # â­ åŠ è½½è®­ç»ƒçš„LoRA
pipe.to("cuda")

# 2. å‡†å¤‡è¾“å…¥å›¾åƒ
image = Image.open(args.image).convert("RGB")
if image.width != 512:
    image = image.resize((512, new_height))  # â­ å¼ºåˆ¶å®½åº¦=512

# 3. æ„é€ Diptych
combined_image = Image.new("RGB", (1024, height))
combined_image.paste(image, (0, 0))     # å·¦è¾¹: åŸå›¾
combined_image.paste(image, (512, 0))   # å³è¾¹: åŸå›¾(å¾…ç¼–è¾‘)

# 4. åˆ›å»ºMask
mask = np.zeros((height, 1024), dtype=np.uint8)
mask[:, 512:] = 255  # å³åŠéƒ¨åˆ†

# 5. æ„é€ Prompt
instruction = f"A diptych with two side-by-side images of the same scene. " \
              f"On the right, the scene is exactly the same as on the left but {args.instruction}"

# 6. æ¨ç†
result = pipe(
    prompt=instruction,
    image=combined_image,
    mask_image=mask,
    height=height,
    width=1024,
    guidance_scale=50,       # â­ é«˜CFG=æ›´å¼ºæŒ‡ä»¤è·Ÿéš
    num_inference_steps=28,
    generator=torch.Generator("cpu").manual_seed(args.seed)
).images[0]

# 7. è£å‰ªå³åŠéƒ¨åˆ†
result = result.crop((512, 0, 1024, height))  # åªä¿ç•™ç¼–è¾‘åçš„å›¾åƒ
```

---

## ğŸ¯ æ ¸å¿ƒè®¾è®¡ç†å¿µ

### 1. **Diptych (åŒè”ç”») è®¾è®¡**
- **åŠ¨æœº**: è®©æ¨¡å‹åŒæ—¶çœ‹åˆ°åŸå›¾å’Œç¼–è¾‘åçš„å›¾ï¼Œå­¦ä¹ "ä¿æŒä¸€è‡´æ€§"
- **æ ¼å¼**: `[åŸå›¾ | ç¼–è¾‘å]` æ°´å¹³æ‹¼æ¥
- **ä¼˜åŠ¿**:
  - éšå¼å­¦ä¹ å›¾åƒå¯¹åº”å…³ç³»
  - æ›´å¥½çš„ID/é£æ ¼ä¿æŒ
  - ç®€åŒ–è®­ç»ƒ(ä¸éœ€è¦æ˜¾å¼å¯¹é½æŸå¤±)

### 2. **Flow Matching è®­ç»ƒ**
```python
# ä¼ ç»Ÿæ‰©æ•£æ¨¡å‹: é¢„æµ‹å™ªå£° Îµ
loss = MSE(model(x_t, t), Îµ)

# Flow Matching: é¢„æµ‹é€Ÿåº¦åœº v
v = x_1 - x_0  # ä»å¹²å‡€å›¾åƒåˆ°å™ªå£°çš„"æµåŠ¨æ–¹å‘"
loss = MSE(model(x_t, t), v)
```

### 3. **Prompt Engineering**
å›ºå®šå‰ç¼€: `"A diptych with two side-by-side images of the same scene. On the right, the scene is exactly the same as on the left but {instruction}"`

- "diptych" â†’ æ˜ç¡®åŒå›¾æ ¼å¼
- "exactly the same" â†’ å¼ºè°ƒä¸€è‡´æ€§
- "but {instruction}" â†’ æŒ‡å®šç¼–è¾‘å†…å®¹

---

## ğŸ”§ è®­ç»ƒå¯åŠ¨

### å‡†å¤‡æ•°æ®
```bash
cd train/parquet
bash prepare.sh  # ä¸‹è½½OmniEditæ•°æ®é›†
```

### å¯åŠ¨è®­ç»ƒ
```bash
cd train
export XFL_CONFIG=train/config/normal_lora.yaml
bash train/script/train.sh
```

**train.sh å†…å®¹** (æ¨æµ‹):
```bash
XFL_CONFIG=train/config/normal_lora.yaml \
python -m torch.distributed.run \
    --nproc_per_node=4 \
    src/train/train.py
```

---

## ğŸ“Š å…³é”®è¶…å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| Image Size | 512Ã—512 | å›ºå®šå®½åº¦512 |
| LoRA Rank | 32 | è¾ƒå¤§=æ›´å¼ºè¡¨è¾¾èƒ½åŠ› |
| Batch Size | 2Ã—4 GPU = 8 | è®ºæ–‡ä¸­æ€»batch=16 (2Ã—2Ã—4) |
| Optimizer | Prodigy (lr=1) | è‡ªé€‚åº”å­¦ä¹ ç‡ |
| CFG Scale | 50 (æ¨ç†) | éå¸¸é«˜=å¼ºæŒ‡ä»¤è·Ÿéš |
| Steps | 28 (æ¨ç†) | FLUXæ ‡å‡†æ­¥æ•° |
| Drop Text Prob | 0.1 | CFGè®­ç»ƒ |

---

## ğŸš€ å¿«é€Ÿå®šä½ä»£ç 

### éœ€è¦ä¿®æ”¹è®­ç»ƒé€»è¾‘?
â†’ `train/src/train/model.py` ç¬¬112-160è¡Œ (`step()` æ–¹æ³•)

### éœ€è¦ä¿®æ”¹æ•°æ®å¤„ç†?
â†’ `train/src/train/data.py` ç¬¬49-84è¡Œ (`__getitem__()` æ–¹æ³•)

### éœ€è¦æ”¹å˜LoRAç›®æ ‡å±‚?
â†’ `train/train/config/normal_lora.yaml` ç¬¬38è¡Œ (`target_modules`)

### éœ€è¦è°ƒæ•´è®­ç»ƒå‚æ•°?
â†’ `train/train/config/normal_lora.yaml`

### éœ€è¦ä¿®æ”¹æ¨ç†æµç¨‹?
â†’ `scripts/inference.py` ç¬¬62-71è¡Œ (pipeè°ƒç”¨)

---

## ğŸ’¡ é‡è¦æ³¨æ„äº‹é¡¹

1. **å›¾åƒå®½åº¦å¿…é¡»æ˜¯512**
   - æ¨¡å‹åœ¨512å®½åº¦ä¸Šè®­ç»ƒ
   - æ¨ç†æ—¶è‡ªåŠ¨resizeåˆ°512

2. **Diptychæ ¼å¼å›ºå®š**
   - è®­ç»ƒ: `[åŸå›¾ | ç¼–è¾‘å›¾]`
   - æ¨ç†: `[åŸå›¾ | åŸå›¾]` â†’ è¾“å‡º `[åŸå›¾ | ç¼–è¾‘å›¾]`

3. **Maskå›ºå®šå³åŠéƒ¨åˆ†**
   ```python
   mask[:, 512:] = 255  # å³åŠéƒ¨åˆ†
   ```

4. **é«˜CFG Scale (50)**
   - è¿œé«˜äºå¸¸è§„æ‰©æ•£æ¨¡å‹(é€šå¸¸7-10)
   - ç”¨äºå¢å¼ºæŒ‡ä»¤è·Ÿéšèƒ½åŠ›

5. **æ•°æ®é›†æ··åˆ**
   - MagicBrush: é«˜è´¨é‡æ ‡æ³¨
   - OmniEdit: å¤§è§„æ¨¡å¤šæ ·æ€§

---

## ğŸ” è°ƒè¯•æŠ€å·§

### æŸ¥çœ‹è®­ç»ƒè¿›åº¦
```bash
# WanDB (éœ€è¦é…ç½®WANDB_API_KEY)
# æˆ–æŸ¥çœ‹æœ¬åœ°æ—¥å¿—
ls train/runs/20250513-*/
```

### æµ‹è¯•å•ä¸ªæ ·æœ¬
```python
from train.src.train.data import EditDataset_with_Omini
dataset = EditDataset_with_Omini(...)
sample = dataset[0]
print(sample.keys())  # image, condition, description
```

### éªŒè¯LoRAåŠ è½½
```python
pipe.load_lora_weights("path/to/lora")
# æ£€æŸ¥æ˜¯å¦æˆåŠŸ
print(pipe.transformer.get_adapter_state_dict())
```

---

## ğŸ“š ç›¸å…³èµ„æº

- **è®ºæ–‡**: https://arxiv.org/abs/2504.20690
- **HuggingFaceæ¨¡å‹**: https://huggingface.co/RiverZ/normal-lora
- **åŸºç¡€ä»£ç **: OminiControl (https://github.com/Yuanshi9815/OminiControl)
- **FLUXæ¨¡å‹**: https://huggingface.co/black-forest-labs/flux.1-fill-dev

---

**æœ€åæ›´æ–°**: 2025-10-04
